# Clinical Perturbation-Aware Knowledge Distillation for Trustworthy Cardiac Image Segmentation

## About
This work presents a perturbation-aware knowledge distillation (KD) framework for trustworthy cardiac CT segmentation. High-capacity teacher model transfers knowledge to a compact student model using three complementary distillation losses. To assess robustness, ten levels of low-dose CT noise were simulted and performance degradation was evaluated. The Trustworthy Robustness Index (TRI) is introduced, a novel metric that quantifies how gracefully segmentation quality degrades. Experiments demonstrate that KD significantly improves student performance on clean data and enhances resilience to noise offering a reliable and efficient solution for clinical deployment.
